{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs\n",
    "Get the files located here for example inputs to pyhf:\n",
    "\n",
    "```\n",
    "https://github.com/vladov3000/pyvshf/tree/master/hfout\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Remove the first line of xml files\n",
    "```\n",
    "MonoJetOut/config/*.xml\n",
    "```\n",
    "You do not need to do this if you are using the data provided in the git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed '14d' ../hfout/config/MyOneBinExample/Exclusion.xml > temp.xml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But be careful, this command above is a hack and \"irreversibly modifies\" the xml config file.  If you run it twice, then it will crash everything when you try to run the xml2json command below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp temp.xml ../hfout/config/MyOneBinExample/Exclusion.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyhf Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the necessary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import pyhf\n",
    "from pyhf import Model,Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the xml workspace from Giuliano to a pyhf compatible JSON spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Documents/EPEprojects/pyvshf/hfout/config/MyOneBinExample/Exclusion.xml\r\n"
     ]
    }
   ],
   "source": [
    "!ls $(realpath ../hfout/config/MyOneBinExample/Exclusion.xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"channels\": [\r\n",
      "        {\r\n",
      "            \"name\": \"SR_cuts\",\r\n",
      "            \"samples\": [\r\n",
      "                {\r\n",
      "                    \"data\": [\r\n",
      "                        1.1137869358062744\r\n",
      "                    ],\r\n",
      "                    \"modifiers\": [\r\n",
      "                        {\r\n",
      "                            \"data\": {\r\n",
      "                                \"hi\": 0.820103,\r\n",
      "                                \"lo\": 1.33253\r\n",
      "                            },\r\n",
      "                            \"name\": \"KtScaleTop\",\r\n",
      "                            \"type\": \"normsys\"\r\n",
      "                        },\r\n",
      "                        {\r\n",
      "                            \"data\": {\r\n",
      "                                \"hi\": 1.26857,\r\n",
      "                                \"lo\": 0.840855\r\n",
      "                            },\r\n",
      "                            \"name\": \"JES\",\r\n",
      "                            \"type\": \"normsys\"\r\n",
      "                        }\r\n",
      "                    ],\r\n",
      "                    \"name\": \"Top\"\r\n",
      "                },\r\n",
      "                {\r\n",
      "                    \"data\": [\r\n",
      "                        3.485983371734619\r\n",
      "                    ],\r\n",
      "                    \"modifiers\": [\r\n",
      "                        {\r\n",
      "                            \"data\": {\r\n",
      "                                \"hi\": 1.16491,\r\n",
      "                                \"lo\": 1.65393\r\n",
      "                            },\r\n",
      "                            \"name\": \"KtScaleWZ\",\r\n",
      "                            \"type\": \"normsys\"\r\n",
      "                        },\r\n",
      "                        {\r\n",
      "                            \"data\": {\r\n",
      "                                \"hi\": 1.23651,\r\n",
      "                                \"lo\": 0.883608\r\n",
      "                            },\r\n",
      "                            \"name\": \"JES\",\r\n",
      "                            \"type\": \"normsys\"\r\n",
      "                        }\r\n",
      "                    ],\r\n",
      "                    \"name\": \"WZ\"\r\n",
      "                },\r\n",
      "                {\r\n",
      "                    \"data\": [\r\n",
      "                        9.279168128967285\r\n",
      "                    ],\r\n",
      "                    \"modifiers\": [\r\n",
      "                        {\r\n",
      "                            \"data\": null,\r\n",
      "                            \"name\": \"lumi\",\r\n",
      "                            \"type\": \"lumi\"\r\n",
      "                        },\r\n",
      "                        {\r\n",
      "                            \"data\": {\r\n",
      "                                \"hi\": 1.17916,\r\n",
      "                                \"lo\": 0.666616\r\n",
      "                            },\r\n",
      "                            \"name\": \"JES\",\r\n",
      "                            \"type\": \"normsys\"\r\n",
      "                        },\r\n",
      "                        {\r\n",
      "                            \"data\": null,\r\n",
      "                            \"name\": \"mu_SIG\",\r\n",
      "                            \"type\": \"normfactor\"\r\n",
      "                        }\r\n",
      "                    ],\r\n",
      "                    \"name\": \"SM_GG_onestepCC_425_385_345\"\r\n",
      "                }\r\n",
      "            ]\r\n",
      "        }\r\n",
      "    ],\r\n",
      "    \"measurements\": [\r\n",
      "        {\r\n",
      "            \"config\": {\r\n",
      "                \"parameters\": [\r\n",
      "                    {\r\n",
      "                        \"auxdata\": [\r\n",
      "                            1.0\r\n",
      "                        ],\r\n",
      "                        \"bounds\": [\r\n",
      "                            [\r\n",
      "                                0.8049999999999999,\r\n",
      "                                1.195\r\n",
      "                            ]\r\n",
      "                        ],\r\n",
      "                        \"inits\": [\r\n",
      "                            1.0\r\n",
      "                        ],\r\n",
      "                        \"name\": \"lumi\",\r\n",
      "                        \"sigmas\": [\r\n",
      "                            0.039\r\n",
      "                        ]\r\n",
      "                    },\r\n",
      "                    {\r\n",
      "                        \"bounds\": [\r\n",
      "                            [\r\n",
      "                                0.0,\r\n",
      "                                5.0\r\n",
      "                            ]\r\n",
      "                        ],\r\n",
      "                        \"fixed\": false,\r\n",
      "                        \"inits\": [\r\n",
      "                            1.0\r\n",
      "                        ],\r\n",
      "                        \"name\": \"mu_SIG\"\r\n",
      "                    }\r\n",
      "                ],\r\n",
      "                \"poi\": \"mu_SIG\"\r\n",
      "            },\r\n",
      "            \"name\": \"NormalMeasurement\"\r\n",
      "        }\r\n",
      "    ],\r\n",
      "    \"observations\": [\r\n",
      "        {\r\n",
      "            \"data\": [\r\n",
      "                3.0\r\n",
      "            ],\r\n",
      "            \"name\": \"SR_cuts\"\r\n",
      "        }\r\n",
      "    ],\r\n",
      "    \"version\": \"1.0.0\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!pyhf xml2json --hide-progress $(realpath ../hfout/config/MyOneBinExample/Exclusion.xml) --basedir $(realpath ../hfout) | tee monojet.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate that the spec you just created is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests, jsonschema\n",
    "workspace = json.load(open('monojet.json'))\n",
    "\n",
    "# This line breaks so I just got the schema from the url\n",
    "# schema = requests.get('https://diana-hep.org/pyhf/schemas/1.0.0/workspace.json').json()\n",
    "schema = {\n",
    "    \"$schema\": \"http://json-schema.org/draft-06/schema#\",\n",
    "    \"$id\": \"https://scikit-hep.org/pyhf/schemas/1.0.0/workspace.json\",\n",
    "    \"$ref\": \"defs.json#/definitions/workspace\"\n",
    "}\n",
    "\n",
    "jsonschema.validate(instance=workspace, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by using the stuff from pyhf (because Giordon says its better in a magic way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyhf.utils.validate(workspace, 'workspace.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = pyhf.Workspace(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now extract the model from the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ws.model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the \"data\" associated with the model.  Note that the \"data\" here has two components :\n",
    "- The observed event counts in a given bin\n",
    "- The NP's that will eventually be constrained.  These are referred to as \"data\" in the pyhf and HF lingo because they are indeed measurements that come from the data (e.g. luminosity, JES).\n",
    "\n",
    "This is a bit of a subtle point and confusing but essential to allow us to get at the technical bits and pieces we are interested in examining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "d = ws.data(m)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the initial values of the nuissance parameters in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.config.suggested_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the value of the likelihood of the model and the data at the value of the NP's that are their initial starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.21114099])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.logpdf(m.config.suggested_init(), d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can toggle the available backends here, which is the machinery that will be used to perform the likelihood minimization.\n",
    "\n",
    "This call will let you know what backends you have at your disposal, and then you can perform the minimization below by choosing from among the entries in this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyhf.tensor.numpy_backend.numpy_backend at 0x10daa8dd0>,\n",
       " <pyhf.optimize.opt_scipy.scipy_optimizer at 0x10daa8e50>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyhf.get_backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the second one, which on Sam's machine is scipy_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this optimizer we will now perform the unconstrained fit, meaning that all NP's and the POI are free to be pulled.\n",
    "\n",
    "This will return the values of the NP's that minimize the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyhf.set_backend(\"numpy\")\n",
    "bfit = pyhf.infer.mle.fit(d, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try scipy backend, though it does not work for me\n",
    "# opt = pyhf.get_backend()[1]\n",
    "# bfit = opt.unconstrained_bestfit(pyhf.utils.loglambdav, d, m, m.config.suggested_init(), m.config.suggested_bounds() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print the values of those NP's.  Note that since the input data is the asimov dataset, they are very close to the input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.90103424e-02, -1.97967784e-01,  7.26203092e-08,  1.00002843e+00,\n",
       "        2.03234500e-15])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can show the \"actual\" data which is the event counts that we are fitting out model to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.46321158])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.expected_actualdata(bfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or we can look at the full \"data\" list, which as we recall is both the event counts and the nuissance parameters which come into the constraint terms in the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.46321158e+00, -1.97967784e-01,  6.90103424e-02,  7.26203092e-08,\n",
       "        1.00002843e+00])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.expected_data(bfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can take the difference between the fitted NPs and the initial values that we started with and that gives us the pull of that NP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.90103424e-02, -1.97967784e-01,  7.26203092e-08,  2.84285566e-05,\n",
       "       -1.00000000e+00])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfit-m.config.suggested_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Point\n",
    "The open, and important point, is that the manner in which the error on a given NP is not well defined here in pyhf it seems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhf",
   "language": "python",
   "name": "pyhf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
